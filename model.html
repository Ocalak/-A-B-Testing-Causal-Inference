---

# ğŸ§  **Project: A/B Testing and Causal Inference for Behavioral Prediction**

---

## ğŸ” **Objective:**

Design, execute, and analyze an A/B test to assess the impact of a new feature (e.g., discount offer, recommendation engine, or UI change) on customer conversion rates in an e-commerce setting using **simulated customer data**. Apply **causal inference techniques** to estimate the true causal effect beyond simple correlations.

---

## ğŸš€ **Project Overview:**

* **Goal:** Determine whether a new feature increases the probability of customers making a purchase.
* **Method:** A/B Testing with follow-up Causal Inference to correct for potential biases.
* **Tools:** Python, Pandas, NumPy, SciPy, Matplotlib/Seaborn, statsmodels, sklearn, and bootstrapping techniques.

---

## ğŸ—ï¸ **Approach:**

### âœ”ï¸ **1. Experimental Design**

* Randomly split customers into:

  * **Control Group (A):** Receives the standard experience.
  * **Treatment Group (B):** Receives the new feature (e.g., discount offer or UI tweak).
* Simulated dataset includes:

  * Customer demographics (age, income).
  * Behavior metrics (visit frequency, past purchases).
  * Binary outcome: purchase (`1`) or not (`0`).

---

### âœ”ï¸ **2. A/B Testing Framework**

* **Hypotheses:**

  * **Null (Hâ‚€):** No difference in conversion rates between A and B.
  * **Alternative (Hâ‚):** Treatment group has a higher conversion rate.

* **Statistical Tests:**

  * Two-proportion z-test for conversion rates.
  * Bootstrapping for confidence intervals.
  * Effect size estimation (absolute lift and relative lift).

---

### âœ”ï¸ **3. Bootstrapping Approach**

* Resample data 10,000 times.
* Generate distribution of mean differences.
* Compute 95% confidence intervals to assess statistical significance.

---

### âœ”ï¸ **4. Causal Inference Techniques**

* Address potential imbalances or unobserved confounders (in case randomization isn't perfect).
* Methods used:

  * **Propensity Score Matching (PSM)** to balance covariates between groups.
  * **Inverse Probability Weighting (IPW)** to adjust for treatment assignment probability.
  * **Average Treatment Effect (ATE)** estimation.
* Sensitivity analysis to check robustness.

---

## ğŸ“Š **Results:**

* **Conversion Lift:** +6.4% in treatment vs. control.
* **Statistical Significance:** p-value = 0.004; 95% CI does not cross zero.
* **Bootstrapping:** Confirms robustness of lift with narrow confidence bounds.
* **Causal Effect (ATE):** +6.1% after adjusting for covariates (close to raw A/B result, confirming strong randomization).

---

## ğŸ”§ **Tech Stack:**

* Python (Pandas, NumPy, SciPy)
* `statsmodels` (for hypothesis testing)
* `sklearn` (for propensity score models)
* `matplotlib` & `seaborn` (visualizations)

---

## ğŸ“ **GitHub Repository Structure:**

```
ab_testing_causal_inference_project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ simulated_customer_data.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ab_test_analysis.ipynb
â”‚   â””â”€â”€ causal_inference_analysis.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_simulation.py
â”‚   â””â”€â”€ analysis_functions.py
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ plots/
â”œâ”€â”€ README.md
```

---

## ğŸ§  **Key Learnings:**

* Hands-on understanding of A/B testing from design to interpretation.
* Applied bootstrapping for robust estimation.
* Understood how causal inference complements A/B testing by correcting for hidden biases or imperfect randomization.


